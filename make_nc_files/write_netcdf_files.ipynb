{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: maricopa\r\n",
      "channels:\r\n",
      "- conda-forge\r\n",
      "- defaults\r\n",
      "dependencies:\r\n",
      "- python=2.7\r\n",
      "- matplotlib\r\n",
      "- jupyter\r\n",
      "- pandas\r\n",
      "- xarray\r\n",
      "- numpy\r\n",
      "- mechanize\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!cat ../environment.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from mechanize import Browser\n",
    "\n",
    "out_path = '../NetCDF/'\n",
    "tr = [y+'-01-01' for y in [str(y) for y in range(1980, 2017)]]\n",
    "tr.append(str(pd.datetime.utcnow().date()))\n",
    "\n",
    "meta = pd.read_csv(\"../sensor_ids.csv\")\n",
    "meta['DEV_ID'] = meta['DEV_ID'].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Rptr. Batt.', 'Precip.', 'Stream PT', 'Non Subm PT', 'Dewpoint',\n",
       "       'Humidity', 'Temperature', 'Bubbler', 'Peak Wind', 'Wind Spd/Dir',\n",
       "       'Wind Dir.', 'Solar Rad.', 'Pressure', 'Status', 'Flasher',\n",
       "       'Ave. Wind', 'Radar', 'Water Temp.'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types = meta.DEV_TYPE.unique()\n",
    "types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# these are the IDs of the precip gages that were removed in Oct 2016\n",
    "for ID in ['4650', '4785', '5280', '5490', '5715', '5820', '6680',]:\n",
    "    meta.loc[meta.DEV_ID==ID, 'DEV_ID'] = '9'+ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEV_ID</th>\n",
       "      <th>DEV_NAME</th>\n",
       "      <th>DEV_TYPE</th>\n",
       "      <th>DEV_DATE</th>\n",
       "      <th>STA_LAT_DMS</th>\n",
       "      <th>STA_LONG_DMS</th>\n",
       "      <th>STA_ELEV</th>\n",
       "      <th>STA_LOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>5098</td>\n",
       "      <td>Winters Wash @ Indian School Rd.</td>\n",
       "      <td>Stream PT</td>\n",
       "      <td>7/14/2005 0:00:00</td>\n",
       "      <td>33 29 37.8</td>\n",
       "      <td>112 55 04.0</td>\n",
       "      <td>1105.0</td>\n",
       "      <td>Indian School Rd. 2 miles E of 411th Ave.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>5265</td>\n",
       "      <td>Coyote Wash</td>\n",
       "      <td>Precip.</td>\n",
       "      <td>11/27/2002 0:00:00</td>\n",
       "      <td>33 41 49.2</td>\n",
       "      <td>112 55 24.9</td>\n",
       "      <td>1805.0</td>\n",
       "      <td>3.5 miles SW of the intrscn. of Aguila and Wic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>6853</td>\n",
       "      <td>Gila @ Estrella Pkwy.</td>\n",
       "      <td>Stream PT</td>\n",
       "      <td>3/1/1993 0:00:00</td>\n",
       "      <td>33 23 20.6</td>\n",
       "      <td>112 23 32.9</td>\n",
       "      <td>905.0</td>\n",
       "      <td>Gila River at Estrella Parkway</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DEV_ID                          DEV_NAME   DEV_TYPE            DEV_DATE  \\\n",
       "248   5098  Winters Wash @ Indian School Rd.  Stream PT   7/14/2005 0:00:00   \n",
       "310   5265                       Coyote Wash    Precip.  11/27/2002 0:00:00   \n",
       "661   6853             Gila @ Estrella Pkwy.  Stream PT    3/1/1993 0:00:00   \n",
       "\n",
       "    STA_LAT_DMS STA_LONG_DMS  STA_ELEV  \\\n",
       "248  33 29 37.8  112 55 04.0    1105.0   \n",
       "310  33 41 49.2  112 55 24.9    1805.0   \n",
       "661  33 23 20.6  112 23 32.9     905.0   \n",
       "\n",
       "                                               STA_LOC  \n",
       "248          Indian School Rd. 2 miles E of 411th Ave.  \n",
       "310  3.5 miles SW of the intrscn. of Aguila and Wic...  \n",
       "661                     Gila River at Estrella Parkway  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skip these types of stations\n",
    "excluded = ['Rptr. Batt.', 'Status', 'Flasher',]\n",
    "\n",
    "id1s = [f[0:-3] for f in os.listdir(out_path)]\n",
    "unprocessed = [s for s in meta.index if (meta.loc[s, 'DEV_ID'] not in id1s) and (meta.loc[s, 'DEV_TYPE'] not in excluded)]\n",
    "meta.iloc[unprocessed].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(unprocessed))\n",
    "write_to_file = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['04/03/1994 22:04:42  107.3094628000.0\\n']\n"
     ]
    }
   ],
   "source": [
    "for j in unprocessed:\n",
    "    name = meta.loc[j, 'DEV_TYPE']\n",
    "    id1 = meta.loc[j, 'DEV_ID']\n",
    "\n",
    "    L = []\n",
    "    for i in range(len(tr)-1):\n",
    "        L0 = fill_form(id1, tr[i], tr[i+1])\n",
    "        while len(L0) == 0:\n",
    "            L0 = fill_form(id1, tr[i], tr[i+1])\n",
    "        if len(L0) > 16:\n",
    "            if len(L) == 0:\n",
    "                L = L0[0:-2]\n",
    "            else:\n",
    "                L.extend(L0[14:-2])\n",
    "    # this one has a bad value\n",
    "    if id1 == '6853':\n",
    "        drop = [l for l in L if '107.3094628000.0' in l]\n",
    "        print drop\n",
    "        L.remove(drop[0])\n",
    "\n",
    "    try:\n",
    "        units, s = get_data(L, name)\n",
    "    except:\n",
    "        if write_to_file:\n",
    "            with open('list_issues.txt', 'a') as issues:\n",
    "                issues.write('\\n')\n",
    "                issues.write(name)\n",
    "                issues.write(id1)\n",
    "                issues.write(','.join(L))\n",
    "            continue\n",
    "        else:\n",
    "            print(name, id1)\n",
    "            break\n",
    "\n",
    "    if (name=='Temperature' or name=='Pressure' or name=='Water Temp.') and s.shape[1] > 1:\n",
    "        s = s.iloc[:,0].to_frame()\n",
    "        units = [units[0]]\n",
    "    elif name == 'Precip.' and s.shape[1] > 1:\n",
    "        s = s.iloc[:,1].to_frame()\n",
    "        units = [units[1]]\n",
    "\n",
    "    # get lat to a float\n",
    "    lat = to_decimal(*[float(lat) for lat in meta.loc[j,'STA_LAT_DMS'].split()])\n",
    "\n",
    "    # get lon to a float and we know it is meant to be in the US so make it negative\n",
    "    lon = -to_decimal(*[float(lon) for lon in meta.loc[j,'STA_LONG_DMS'].split()])\n",
    "\n",
    "    # get elevation as a float\n",
    "    elev = float(meta.loc[j,'STA_ELEV'])\n",
    "\n",
    "    ds = to_ds(s, lat, lon, elev, units, name)\n",
    "    ds.attrs.update(meta.loc[j].to_dict())\n",
    "    ds.to_netcdf('{out_path}{id1}.nc'.format(out_path=out_path, id1=id1), format='netCDF4', engine='netcdf4')\n",
    "    print id1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fill_form(id1, start, end):\n",
    "    br = Browser()\n",
    "    br.open(\"http://alert.fcd.maricopa.gov/showrpts_mc.html\")\n",
    "\n",
    "    for i, f in enumerate(br.forms()):\n",
    "        if i==0:\n",
    "            continue\n",
    "        else:\n",
    "            br.form =f\n",
    "\n",
    "    br.form.set_value(id1, name=\"ID1\", type=\"text\")  \n",
    "\n",
    "    #set start time and date\n",
    "    br.form.set_value([start[5:7]], name=\"ms\")\n",
    "    br.form.set_value([start[8:10]], name=\"ds\")\n",
    "    br.form.set_value([start[0:4]], name=\"ys\")\n",
    "    br.form.set_value([\"00:00:00\"], name=\"hs\")\n",
    "\n",
    "    #set end time and date\n",
    "    br.form.set_value([end[5:7]], name=\"ME\")\n",
    "    br.form.set_value([end[8:10]], name=\"DE\")\n",
    "    br.form.set_value([end[0:4]], name=\"YE\")\n",
    "    br.form.set_value([\"24:00:00\"], name=\"HE\")\n",
    "    response = br.submit()  # submit current form\n",
    "    L = [l for l in response.readlines()]\n",
    "    \n",
    "    return L\n",
    "\n",
    "def get_data(L, name):\n",
    "    s = pd.DataFrame([l.split() for l in L[14:-2]])\n",
    "    cols = [l.strip() for l in L[13].split('  ') if l.strip()]\n",
    "    cols.extend(range(s.shape[1]-len(cols)))\n",
    "    s.columns = cols\n",
    "    \n",
    "    # data are in mountain time with no daylight savings so convert to UTC\n",
    "    dt_index = pd.DatetimeIndex(s['Date']+' '+s['Time'])+pd.DateOffset(hours=7)\n",
    "    s = s.set_index(dt_index).drop(['Date','Time'], axis=1)\n",
    "    s.index.name='time'\n",
    "    \n",
    "    # change the name of the data variable from units to the actual name\n",
    "    units = list(s.columns)\n",
    "    \n",
    "    if name == 'Stream PT' or name=='Non Subm PT' or name=='Bubbler' or name=='Radar':\n",
    "        if len(units)==1 and units[0]=='feet':\n",
    "            s.columns = ['stage']\n",
    "        elif units[0]=='feet':\n",
    "            s.columns = ['stage', 'discharge']\n",
    "            units[1]='cfs'\n",
    "        \n",
    "    else:\n",
    "        name = L[7].strip()\n",
    "        s.columns = [name]*len(s.columns)\n",
    "    \n",
    "    # convert to float\n",
    "    s = s.astype('float')\n",
    "    s = s.sort_index()\n",
    "    return(units, s)\n",
    "    \n",
    "def to_decimal(degree, minute, second):\n",
    "    return(degree+(minute/60.)+(second/3600.))\n",
    "\n",
    "def to_ds(s, lat, lon, elev, units, name):\n",
    "    \n",
    "    ds = s.to_xarray()\n",
    "    ds['lat'] = lat\n",
    "    ds['lon'] = lon\n",
    "    ds['elev'] = elev\n",
    "    ds.set_coords(['time','lat','lon', 'elev'], inplace=True)\n",
    "    if s.shape[0] < 20:\n",
    "        chunk=1\n",
    "    else:\n",
    "        chunk = s.shape[0]/20\n",
    "    print(name)\n",
    "    if name == 'Precip.':\n",
    "        attrs = [{'standard_name': 'rainfall'}]\n",
    "    elif name == 'Temperature':\n",
    "        attrs = [{'standard_name': 'air_temperature'}]\n",
    "    elif name == 'Dewpoint':\n",
    "        attrs = [{'standard_name': 'dew_point_temperature'}]\n",
    "    elif name == 'Stream PT'or name == 'Non Subm PT' or name=='Bubbler' or name=='Radar':\n",
    "        attrs = [{'standard_name': 'water_elevation'}, \n",
    "                 {'standard_name':'discharge'}]\n",
    "    elif name == 'Humidity':\n",
    "        attrs = [{'standard_name': 'relative_humidity'}]\n",
    "    elif (name == 'Ave. Wind' or name == 'Wind Spd/Dir') and units[0] == 'miles per hour':\n",
    "        attrs = [{'standard_name': 'wind_speed'}]\n",
    "    elif name == 'Peak Wind':\n",
    "        attrs = [{'standard_name': 'max_wind_speed'}]\n",
    "    elif name == 'Wind Dir.':\n",
    "        attrs = [{'standard_name': 'wind_from_direction'}]\n",
    "    elif name == 'Solar Rad.':\n",
    "        attrs = [{'standard_name': 'solar_radiation'}]\n",
    "    elif name == 'Pressure':\n",
    "        attrs = [{'standard_name': 'air_pressure'}]\n",
    "    elif name == 'Water Temp.':\n",
    "        attrs = [{'standard_name': 'water_temperature'}]\n",
    "        \n",
    "    for i, u in enumerate(units):\n",
    "        if u == 'degrees F' or u == 'degreesF':\n",
    "            attrs[i].update({'units': 'degF'})\n",
    "        elif u == 'inches':\n",
    "            attrs[i].update({'units': 'inch'})\n",
    "        else:\n",
    "            attrs[i].update({'units':  u})\n",
    "        \n",
    "    for i, v in enumerate(ds.data_vars.keys()):\n",
    "        ds[v].attrs.update(attrs[i])\n",
    "        ds[v].encoding.update({'dtype': np.double,'chunksizes':(chunk,),'zlib': True})\n",
    "    ds.lat.attrs.update({'units': 'degrees_north',\n",
    "                         'axis': 'Y',\n",
    "                         'long_name': 'latitude',\n",
    "                         'standard_name': 'latitude'})\n",
    "    ds.lat.encoding.update({'dtype': np.double,'chunksizes':(chunk,),'zlib': True})\n",
    "    ds.lon.attrs.update({'units': 'degrees_east',\n",
    "                         'axis': 'X',\n",
    "                         'long_name': 'longitude',\n",
    "                         'standard_name': 'longitude'})\n",
    "    ds.lon.encoding.update({'dtype': np.double,'chunksizes':(chunk,),'zlib': True})\n",
    "\n",
    "    ds.elev.attrs.update({'units': 'feet',\n",
    "                         'axis': 'Z',\n",
    "                         'long_name': 'elevation',\n",
    "                         'standard_name': 'elevation'})\n",
    "    ds.elev.encoding.update({'dtype': np.double,'chunksizes':(chunk,),'zlib': True})\n",
    "    ds.time.encoding.update({'units':'seconds since 1970-01-01', \n",
    "                             'calendar':'gregorian',\n",
    "                             'dtype': np.double,'chunksizes':(chunk,),'zlib': True})\n",
    "\n",
    "    ds.attrs.update({ 'institution': 'Data from Flood Control District of Maricopa County, hosted by Princeton University',\n",
    "                      'references': 'http://alert.fcd.maricopa.gov/showrpts_mc.html',\n",
    "                      'featureType': 'timeSeries',\n",
    "                      'Conventions': 'CF-1.6',\n",
    "                      'history': 'Created by Princeton University Hydrometeorology Group at {now} '.format(now=pd.datetime.now()),\n",
    "                      'author': 'jsignell@princeton.edu'})\n",
    "    return(ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
